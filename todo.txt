支持每行数据增加RowKing(update,delete,insert,replace)
output能够感知到Input ???,或是感知至Input的columns DataType ???
整库同步工具,或是用参数生成InputsOutputs ???
InputsOutputs配置文件生成工具
集成runner with xstream
xstream集成参数generator
WhereProcessor改名:  SqlExprProcessor SqlFuncProcessor???
记录并使用数据库己知的数据类型
自动create table建表时，使用模板？？？然后SQL代码，只替换表名？
自动建表时，支持partition? (mysql)
JdbcOutput replace数据时，其它数据库，使用insert or update by get data
支持多进程？？ 表字段同步？
支持调整同步并发数？

#Bean2MapProcessor
#表字段同步工具，自动添加字段

增加参数生成功能，如-DparamGenerator=somepkg.SomeClass.method
临时目录支持projectCode及多租户目录，如 /tmp/hivetmp/$projectCode/$zh/xxxxx.tmp.file

支持csv StreamOutput
StreamOutput使用 #号,以支持注释
script 需要增加 context, beforeScript put var into context for init.
	script user context

增加提供中间交换使用的 storage
增加存储状态(如offset)的storage





数据库增量同步
	时间
		天,已经支持
			按时间：日期，同步昨天数据，需要数据有last_update_time，参数要有: start_time & end_time
		分钟
			按时间：分钟，同步上一分钟的数据，需要数据有last_update_time，参数要有: start_time & end_time
			按主键，主键 > last_value,开始数据同步，同步完，更新last_value
	ID
			
	
数据库增量同步,sqoop方式：
  // –incremental 参数为append，–last-value参数为5201314即可。表示只从order_id大于5201314后开始导入。
  --incremental append 
  --check-column order_id 
  --last-value 5201314
  // –incremental 参数为lastmodified，数据可能修改，需要根据merge-key数据合并，再导入数据
  --incremental lastmodified 
  --merge-key order_id //将后续新的记录与原有记录合并。
  --check-column time 
  --last-value “2014-11-09 21:00:00”
 
 支持其它:
  ES
  Hbase
  MongoDB
  Hive
  Kudu
  OpenTSDB
  Cassandra
  #ClickHouse
  